{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd07ec3019a7cb8f5739f8b27d55fc304c51580b268fd2b34191f81e31e11772118",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from re import search\n",
    "import codecs\n",
    "import sys\n",
    "import string"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = []\n",
    "prefixes = []\n",
    "postfixes = []\n",
    "verb_roots = []\n",
    "common_words = []\n",
    "plural_singular = []\n",
    "\n",
    "\n",
    "def read_dataset(path, name):\n",
    "    df = pd.read_excel(path + name)\n",
    "    return df\n",
    "\n",
    "def read_files():\n",
    "    path = 'files/'\n",
    "\n",
    "    #stop_words\n",
    "    name = 'stop_words.txt'\n",
    "    f = open(path + name, 'r', encoding='utf-8')\n",
    "    Lines = f.read().splitlines()\n",
    "    # Strips the newline character\n",
    "    for line in Lines:\n",
    "        stop_words.append(line)\n",
    "    f.close()\n",
    "\n",
    "    #prefixes\n",
    "    name = 'prefixes.txt'\n",
    "    f = open(path + name, 'r', encoding='utf-8')\n",
    "    Lines = f.read().splitlines()\n",
    "    # Strips the newline character\n",
    "    for line in Lines:\n",
    "        prefixes.append(line)\n",
    "    f.close()\n",
    "\n",
    "    #postfixes\n",
    "    name = 'postfixes.txt'\n",
    "    f = open(path + name, 'r', encoding='utf-8')\n",
    "    Lines = f.read().splitlines()\n",
    "    # Strips the newline character\n",
    "    for line in Lines:\n",
    "        postfixes.append(line)\n",
    "    f.close()\n",
    "\n",
    "    # verb_roots\n",
    "    name = 'verb.txt'\n",
    "    f = open(path + name, 'r', encoding='utf-8')\n",
    "    Lines = f.read().splitlines()\n",
    "    count = 0\n",
    "    # Strips the newline character\n",
    "    for line in Lines:\n",
    "        line = line.split('-')\n",
    "        verb_roots.append(line)\n",
    "    f.close()\n",
    "\n",
    "    #common_words\n",
    "    name = 'common_words.txt'\n",
    "    f = open(path + name, 'r', encoding='utf-8')\n",
    "    Lines = f.read().splitlines()\n",
    "    # Strips the newline character\n",
    "    for line in Lines:\n",
    "        common_words.append(line)\n",
    "    f.close()\n",
    "\n",
    "    #plural_singular\n",
    "    name = 'plural_singular.txt'\n",
    "    f = open(path + name, 'r', encoding='utf-8')\n",
    "    Lines = f.read().splitlines()\n",
    "    count = 0\n",
    "    # Strips the newline character\n",
    "    for line in Lines:\n",
    "        line = line.split('-')\n",
    "        plural_singular.append(line)\n",
    "    f.close()\n",
    "\n",
    "def delete_punctuations(doc):\n",
    "    punctuations = '،:؛؟!»«()[]\"*,{.}@!?/'\n",
    "    edited_doc = doc.translate(str.maketrans('', '', punctuations))\n",
    "    edited_doc = doc.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    return edited_doc\n",
    "\n",
    "def delete_stopWords(doc):\n",
    "    edited_doc = doc\n",
    "    for s in stop_words:\n",
    "        my_regex = r\"\\b\"+s+r\"\\b\"\n",
    "        edited_doc = re.sub(my_regex , \"\", edited_doc)\n",
    "    return edited_doc\n",
    "\n",
    "def delete_highFrequencyWords(inverted_indexes):\n",
    "    df_temp = df.copy()\n",
    "    for i in inverted_indexes:\n",
    "        if len(i[1])/len(df_temp) > 0.8:\n",
    "            inverted_indexes.remove(i)\n",
    "    return inverted_indexes\n",
    "\n",
    "def delete_postfixes(doc):\n",
    "    edited_doc = doc\n",
    "    for p in postfixes:\n",
    "        my_regex = p + r\"\\b\"\n",
    "        edited_doc = re.sub(my_regex , \"\", edited_doc)\n",
    "    return edited_doc\n",
    "\n",
    "def delete_prefixes(doc):\n",
    "    edited_doc = doc\n",
    "    for p in postfixes:\n",
    "        my_regex = r\"\\b\" + p\n",
    "        edited_doc = re.sub(my_regex , \"\", edited_doc)\n",
    "    return edited_doc\n",
    "\n",
    "def replaceWithRoot(tokens):   \n",
    "    for i in range(0, len(tokens)):\n",
    "        for root in verb_roots:\n",
    "            if search(root[0], tokens[i]) or search(root[1], tokens[i]):\n",
    "                common = False\n",
    "                for c in common_words:\n",
    "                    if c == tokens[i]:\n",
    "                        common = True\n",
    "                        print(\"common\")\n",
    "                        break\n",
    "                if common == False:\n",
    "                    print(\"root\")\n",
    "                    tokens[i] = tokens[i].replace(tokens[i], root[2])\n",
    "\n",
    "    return tokens\n",
    "\n",
    "def replaceArabicWords(doc):\n",
    "    doc = doc.replace('ك', 'ک')\n",
    "    doc = doc.replace('ئ', 'ی')\n",
    "    doc = doc.replace('ي', 'ی')\n",
    "    doc = doc.replace('ؤ', 'و')\n",
    "    doc = doc.replace('هٔ', 'ه')\n",
    "    doc = doc.replace('ة', 'ه')\n",
    "    doc = doc.replace('آ', 'ا')\n",
    "    doc = doc.replace('أ', 'ا')\n",
    "    doc = doc.replace('إ', 'ا')\n",
    "    return doc\n",
    "\n",
    "def pluralToSingular(tokens):\n",
    "    for i in range(0, len(tokens)):\n",
    "        for ps in plural_singular:\n",
    "            if search(ps[0], tokens[i]):\n",
    "                tokens[i] = tokens[i].replace(tokens[i], ps[1])\n",
    "    return tokens\n",
    "\n",
    "def tokenize(df):\n",
    "    content = df.content\n",
    "\n",
    "    tokens = []\n",
    "    for i in range(0, content.size):\n",
    "        doc = content[i]\n",
    "        # 68000 tokens\n",
    "        doc = delete_punctuations(doc)\n",
    "        # 50000 tokens\n",
    "        doc = delete_stopWords(doc)\n",
    "\n",
    "        doc = replaceArabicWords(doc)\n",
    "\n",
    "        doc = delete_postfixes(doc)\n",
    "\n",
    "        doc = delete_prefixes(doc)\n",
    "        \n",
    "        tokenized_doc = doc.split()\n",
    "        tokenized_doc = replaceWithRoot(tokenized_doc)\n",
    "        tokenized_doc = pluralToSingular(tokenized_doc)\n",
    "\n",
    "        for token in tokenized_doc:\n",
    "            temp = []\n",
    "            temp.append(token)\n",
    "            temp.append(df.id[i])\n",
    "            tokens.append(temp)\n",
    "    tokens.sort()\n",
    "    return tokens\n",
    "\n",
    "def create_inverted_indexes(tokens):\n",
    "    inverted_indexes = []\n",
    "    doc_temp = []\n",
    "    token_temp = \"\"\n",
    "    for token in tokens:\n",
    "        if token[0] == token_temp:\n",
    "            doc_temp.append(token[1])\n",
    "        else:\n",
    "            temp = []\n",
    "            temp.append(token_temp)\n",
    "            doc_temp = set(doc_temp)\n",
    "            temp.append(doc_temp)\n",
    "            inverted_indexes.append(temp)\n",
    "            doc_temp = []\n",
    "\n",
    "        token_temp = token[0]\n",
    "        # if len(doc_temp) > 0 and token[1] != doc_temp[-1]:\n",
    "        doc_temp.append(token[1])\n",
    "    \n",
    "    inverted_indexes = delete_highFrequencyWords(inverted_indexes)\n",
    "    return inverted_indexes\n",
    "\n",
    "def search_token(inverted_indexes, token_name):\n",
    "    for token in inverted_indexes:\n",
    "        if token[0] == token_name:\n",
    "            return token[1]\n",
    "    print(\"this token not exist in our database\")\n",
    "\n",
    "def print_res(df, res):\n",
    "    p_res = pd.DataFrame()\n",
    "\n",
    "    p_res = pd.merge(df, res, on=['id'], how='inner')\n",
    "    our_res = p_res[['id', 'rank', 'url']]\n",
    "    our_res = our_res.sort_values([\"rank\"], ascending=False)\n",
    "\n",
    "    print(our_res)\n",
    "    \n",
    "\n",
    "def query_processing(df, inverted_indexes, query):\n",
    "    res = []\n",
    "    docs_id = pd.DataFrame()\n",
    "\n",
    "\n",
    "    query = delete_punctuations(query)\n",
    "    query = delete_stopWords(query)\n",
    "    query = delete_postfixes(query)\n",
    "    query = delete_prefixes(query)\n",
    "    query = replaceArabicWords(query)\n",
    "\n",
    "    tokenized_query = query.split()\n",
    "    tokenized_query = replaceWithRoot(tokenized_query)\n",
    "    tokenized_query = pluralToSingular(tokenized_query)\n",
    "\n",
    "    if len(tokenized_query) == 0:\n",
    "        print(\"It looks like there aren't many great matches for your search\")\n",
    "        return\n",
    "\n",
    "\n",
    "    for i in range (0 ,len(tokenized_query)):\n",
    "        temp_docs_id = pd.DataFrame(search_token(inverted_indexes, tokenized_query[i]))\n",
    "        docs_id = pd.DataFrame(docs_id.append(temp_docs_id))\n",
    "\n",
    "    docs_id = docs_id[0].value_counts().reset_index()\n",
    "    docs_id.columns = ['id', 'rank']\n",
    "    print_res(df, docs_id)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_dataset(\"datasets/\", \"IR_Spring2021_ph12_7k.xlsx\")\n",
    "read_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n",
      "common\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenize(df)\n",
    "inverted_indexes = create_inverted_indexes(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1701668\n49324\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))\n",
    "print(len(inverted_indexes))\n",
    "\n",
    "# for i in range(5000, 5100):\n",
    "#     print(inverted_indexes[i][0])\n",
    "#     print(inverted_indexes[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{27,\n",
       " 66,\n",
       " 94,\n",
       " 184,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 234,\n",
       " 243,\n",
       " 250,\n",
       " 265,\n",
       " 307,\n",
       " 403,\n",
       " 412,\n",
       " 414,\n",
       " 441,\n",
       " 481,\n",
       " 487,\n",
       " 493,\n",
       " 499,\n",
       " 546,\n",
       " 548,\n",
       " 555,\n",
       " 558,\n",
       " 578,\n",
       " 586,\n",
       " 602,\n",
       " 612,\n",
       " 614,\n",
       " 632,\n",
       " 640,\n",
       " 641,\n",
       " 649,\n",
       " 654,\n",
       " 658,\n",
       " 663,\n",
       " 676,\n",
       " 694,\n",
       " 698,\n",
       " 704,\n",
       " 708,\n",
       " 711,\n",
       " 747,\n",
       " 754,\n",
       " 760,\n",
       " 800,\n",
       " 806,\n",
       " 817,\n",
       " 877,\n",
       " 893,\n",
       " 895,\n",
       " 900,\n",
       " 902,\n",
       " 912,\n",
       " 914,\n",
       " 921,\n",
       " 923,\n",
       " 928,\n",
       " 946,\n",
       " 951,\n",
       " 962,\n",
       " 983,\n",
       " 1006,\n",
       " 1007,\n",
       " 1019,\n",
       " 1022,\n",
       " 1026,\n",
       " 1028,\n",
       " 1037,\n",
       " 1046,\n",
       " 1063,\n",
       " 1068,\n",
       " 1080,\n",
       " 1086,\n",
       " 1094,\n",
       " 1104,\n",
       " 1124,\n",
       " 1130,\n",
       " 1138,\n",
       " 1174,\n",
       " 1211,\n",
       " 1213,\n",
       " 1223,\n",
       " 1240,\n",
       " 1288,\n",
       " 1311,\n",
       " 1345,\n",
       " 1353,\n",
       " 1354,\n",
       " 1355,\n",
       " 1357,\n",
       " 1358,\n",
       " 1363,\n",
       " 1368,\n",
       " 1372,\n",
       " 1379,\n",
       " 1397,\n",
       " 1400,\n",
       " 1401,\n",
       " 1418,\n",
       " 1456,\n",
       " 1467,\n",
       " 1503,\n",
       " 1506,\n",
       " 1536,\n",
       " 1540,\n",
       " 1552,\n",
       " 1578,\n",
       " 1603,\n",
       " 1610,\n",
       " 1630,\n",
       " 1637,\n",
       " 1644,\n",
       " 1662,\n",
       " 1663,\n",
       " 1672,\n",
       " 1717,\n",
       " 1778,\n",
       " 1882,\n",
       " 1892,\n",
       " 1948,\n",
       " 1962,\n",
       " 2048,\n",
       " 2099,\n",
       " 2137,\n",
       " 2149,\n",
       " 2252,\n",
       " 2361,\n",
       " 2458,\n",
       " 2496,\n",
       " 2532,\n",
       " 2651,\n",
       " 2696,\n",
       " 2704,\n",
       " 2705,\n",
       " 2714,\n",
       " 2764,\n",
       " 2769,\n",
       " 2968,\n",
       " 3031,\n",
       " 3128,\n",
       " 3152,\n",
       " 3225,\n",
       " 3257,\n",
       " 3529,\n",
       " 3553,\n",
       " 3661,\n",
       " 3665,\n",
       " 3758,\n",
       " 3767,\n",
       " 3937,\n",
       " 3947,\n",
       " 3968,\n",
       " 3974,\n",
       " 3997,\n",
       " 4040,\n",
       " 4194,\n",
       " 4214,\n",
       " 4320,\n",
       " 4341,\n",
       " 4342,\n",
       " 4405,\n",
       " 4407,\n",
       " 4461,\n",
       " 4541,\n",
       " 4547,\n",
       " 4594,\n",
       " 4714,\n",
       " 4751,\n",
       " 4753,\n",
       " 4855,\n",
       " 4990,\n",
       " 5002,\n",
       " 5332,\n",
       " 5444,\n",
       " 5579,\n",
       " 5758,\n",
       " 5766,\n",
       " 5845,\n",
       " 5914,\n",
       " 6026,\n",
       " 6708,\n",
       " 6793,\n",
       " 6798,\n",
       " 6801,\n",
       " 6887,\n",
       " 6890}"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "search_token(inverted_indexes, \"مید\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       id  rank                                                url\n0      27     1  https://www.isna.ir/news/99011005164/روایت-روز...\n128  2458     1  https://www.isna.ir/news/99112619458/بررسی-طرح...\n119  1892     1  https://www.isna.ir/news/99041511345/ساماندهی-...\n120  1948     1  https://www.isna.ir/news/99051309792/دستور-داد...\n121  1962     1  https://www.isna.ir/news/99051813039/شمخانی-نم...\n..    ...   ...                                                ...\n64   1019     1  https://www.isna.ir/news/99122116413/قرعه-کشی-...\n65   1022     1  https://www.isna.ir/news/99122216793/حذف-عسگری...\n66   1026     1  https://www.isna.ir/news/99122418504/پایان-کار...\n67   1028     1  https://www.isna.ir/news/99122620408/فولاد-سیر...\n186  6890     1  https://www.isna.ir/news/98071713455/برای-اهدا...\n\n[187 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "query = \"مید\"\n",
    "query_processing(df, inverted_indexes, query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}